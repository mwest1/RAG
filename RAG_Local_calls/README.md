This project the first phase of a local LLM system.

The assumption is that Ollama is running locally. 
